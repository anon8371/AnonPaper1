{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trenton/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_net' from 'py_scripts.utils_DL' (/home/trenton/Foundational-SDM/py_scripts/utils_DL.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cbe9017371a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../py_scripts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpy_scripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils_DL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMNISTDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpy_scripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelStyles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKDecayOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_net' from 'py_scripts.utils_DL' (/home/trenton/Foundational-SDM/py_scripts/utils_DL.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path.append('../py_scripts')\n",
    "import matplotlib.pyplot as plt\n",
    "from py_scripts.utils_DL import get_net, MNISTDataModule\n",
    "import pytorch_lightning as pl\n",
    "from py_scripts.params import get_params, ModelStyles, DataSet, KDecayOptions\n",
    "import wandb\n",
    "import torch \n",
    "from torch import nn\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import numpy as np\n",
    "\n",
    "# gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReLU()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.EmbeddingBag(100, 10, mode='sum').weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of implicit keys 1000\n",
      "torch.Size([10, 3, 20]) torch.Size([128, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "key_len = 60\n",
    "n_explicit_keys_per_chunk = 10\n",
    "nchunks = 3\n",
    "k = 5\n",
    "nimplicit_keys = n_explicit_keys_per_chunk**nchunks\n",
    "assert key_len%nchunks==0, \"Need chunks to be evenly divisible.\"\n",
    "print(\"Number of implicit keys\", nimplicit_keys)\n",
    "sub_ks = torch.randn((n_explicit_keys_per_chunk, nchunks,key_len//nchunks))\n",
    "inputs = torch.randn((128,key_len))\n",
    "sub_qs = torch.stack(torch.chunk(inputs, nchunks, dim=1),dim=1)\n",
    "print(sub_ks.shape, sub_qs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norm each of the sub components\n",
    "\n",
    "# TODO: see if the method implemented in the FAIR library is faster. \n",
    "\n",
    "sub_ks /= torch.norm(sub_ks, dim=-1, keepdim=True)\n",
    "sub_qs /= torch.norm(sub_qs, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 60])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_inputs = sub_qs.flatten(start_dim=1)\n",
    "full_inputs.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_ks torch.Size([1000, 60])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([17, 57, 27, 18, 58])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ground truth test:\n",
    "\n",
    "for i in range(nchunks-1):\n",
    "    nreps = n_explicit_keys_per_chunk**(i+1)\n",
    "    if i==0:\n",
    "        one = sub_ks[:,i:i+1,:].repeat_interleave(nreps,0)\n",
    "        two = sub_ks[:,i+1:i+2,:].tile((nreps,1,1))\n",
    "        full_ks = torch.concat([one, two], dim=-1)\n",
    "    else: \n",
    "        full_ks = full_ks.repeat_interleave(n_explicit_keys_per_chunk**i,0)\n",
    "        next = sub_ks[:,i+1:i+2,:].tile((nreps,1,1))\n",
    "        full_ks = torch.concat([full_ks, next], dim=-1)\n",
    "full_ks = full_ks.squeeze()\n",
    "    \n",
    "print(\"full_ks\", full_ks.shape )\n",
    "# L2 norm each of the sub components\n",
    "\n",
    "full_ks /= torch.norm(full_ks, dim=-1, keepdim=True)\n",
    "full_inputs /= torch.norm(full_inputs, dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "fsims = torch.matmul(full_ks, full_inputs.T).T\n",
    "fvals, finds = torch.topk(fsims, k, dim=-1)\n",
    "target_vals = finds[0]\n",
    "target_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1688, -0.0007, -0.1307, -0.0585,  0.1896,  0.0085,  0.0352,  0.1662,\n",
       "        -0.1187,  0.0198])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ks[30][30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 20])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_ks.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2923, -0.0012, -0.2264, -0.1014,  0.3284,  0.0147,  0.0610,  0.2878,\n",
       "        -0.2057,  0.0342])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_ks[3,1,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 60])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 20])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_ks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 10])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunks, batch, neurons\n",
    "sims = torch.einsum('ncd,bcd->bcn', sub_ks, sub_qs)\n",
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 5])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sub_sims, inds = torch.topk(sims, k, dim=-1)\n",
    "inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 9, 1, 6, 8],\n",
       "        [1, 5, 2, 3, 8],\n",
       "        [7, 8, 1, 2, 4]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[100.],\n",
       "         [ 10.],\n",
       "         [  1.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_index_mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 57, 27, 18, 58])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 125])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_res = None\n",
    "# TODO: make this faster. maybe using:\n",
    "# I am doing the smae thing but broadcasting and can work with more keys though. there is another implementation that is even better somewhere? \n",
    "\n",
    "for i in range(nchunks-1):\n",
    "    if i ==0:\n",
    "        sum_res = (top_sub_sims[:, i, :].unsqueeze(2) + top_sub_sims[:, i+1, :].unsqueeze(1)).flatten(start_dim=1)\n",
    "    else: \n",
    "        sum_res = (sum_res.unsqueeze(2) + top_sub_sims[:, i+1, :].unsqueeze(1)).flatten(start_dim=1)\n",
    "sum_res.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 5]), tensor([ 0,  5, 10,  1,  6]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_vals, sum_inds = torch.topk(sum_res, k, dim=-1)\n",
    "# need to map these indices back to their original combos. \n",
    "sum_inds.shape, sum_inds[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [1, 5, 2, 1, 5],\n",
       "        [7, 7, 7, 8, 8]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_inds = []\n",
    "relative_index_mags = [(k**(nchunks -i-1)) for i in range(nchunks)]\n",
    "for mag in relative_index_mags:\n",
    "    amount = sum_inds //mag\n",
    "    # remainder\n",
    "    sum_inds = sum_inds - (amount*mag)\n",
    "    relative_inds.append( amount )\n",
    "og_inds = torch.gather(inds, -1, torch.stack(relative_inds,dim=1))\n",
    "og_inds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of py_scripts.utils_DL failed: Traceback (most recent call last):\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/trentonbricken/Foundational-SDM/py_scripts/utils_DL.py\", line 3, in <module>\n",
      "    from py_scripts import KDecayOptions, ModelStyles\n",
      "ImportError: cannot import name 'KDecayOptions' from 'py_scripts' (unknown location)\n",
      "]\n",
      "[autoreload of params failed: Traceback (most recent call last):\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"../py_scripts/params.py\", line 6, in <module>\n",
      "    from models import DEEP_SDM, SDM_FFN, ProductKeys\n",
      "  File \"/Users/trentonbricken/Foundational-SDM/models/__init__.py\", line 1, in <module>\n",
      "    from .Base_Model import BaseModel\n",
      "  File \"/Users/trentonbricken/Foundational-SDM/models/Base_Model.py\", line 10, in <module>\n",
      "    from py_scripts import KDecayOptions\n",
      "ImportError: cannot import name 'KDecayOptions' from 'py_scripts' (unknown location)\n",
      "]\n",
      "[autoreload of py_scripts.params failed: Traceback (most recent call last):\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/trentonbricken/anaconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/trentonbricken/Foundational-SDM/py_scripts/params.py\", line 6, in <module>\n",
      "    from models import DEEP_SDM, SDM_FFN, ProductKeys\n",
      "  File \"/Users/trentonbricken/Foundational-SDM/models/__init__.py\", line 1, in <module>\n",
      "    from .Base_Model import BaseModel\n",
      "  File \"/Users/trentonbricken/Foundational-SDM/models/Base_Model.py\", line 10, in <module>\n",
      "    from py_scripts import KDecayOptions\n",
      "ImportError: cannot import name 'KDecayOptions' from 'py_scripts' (unknown location)\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 5]), torch.Size([128, 5]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_inds.shape, sum_vals.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 57, 27, 18, 58])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_index_mags = [(n_explicit_keys_per_chunk**(nchunks -i-1)) for i in range(nchunks)]\n",
    "og_index_mags = torch.Tensor(og_index_mags).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "implicit_neuron_inds = (og_inds * og_index_mags).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17., 57., 27., 18., 58.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_neuron_inds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 57, 27, 18, 58])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b79e30f1293356f40e6101fd4857a1e3851d48caf36daef1a794617153a89eff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
